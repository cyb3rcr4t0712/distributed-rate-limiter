# Distributed Rate Limiting Service

A production-ready distributed rate limiting backend service built with **FastAPI** and **Redis**.  
Enforces API request quotas using a **sliding window algorithm** â€” stateless, horizontally scalable, and cloud-native.

![Python](https://img.shields.io/badge/python-3.11-blue)
![FastAPI](https://img.shields.io/badge/FastAPI-0.128-green)
![Redis](https://img.shields.io/badge/Redis-7.x-red)
![License](https://img.shields.io/badge/license-MIT-blue)

---

## ğŸ¯ Problem Statement

In large-scale backend systems, APIs must be protected from abuse, accidental overuse, and denial-of-service scenarios.  
This service provides **centralized, distributed rate limiting** that can be shared across multiple API instances.

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Client    â”‚â”€â”€â”€â”€â–¶â”‚   FastAPI   â”‚â”€â”€â”€â”€â–¶â”‚    Redis    â”‚
â”‚  (API Key)  â”‚     â”‚  (Stateless)â”‚     â”‚ (State Store)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”
                    â”‚  Lua Script â”‚
                    â”‚  (Atomic)   â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Key Design Decisions:**
- **Sliding Window Algorithm** â€” Precise request counting, avoids fixed-window burst issues
- **Atomic Lua Scripts** â€” Race-condition-free Redis operations in a single round-trip
- **Stateless API** â€” Horizontally scalable, Redis handles all coordination

---

## ğŸ“ Project Structure

```
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py           # FastAPI app + rate limit middleware
â”‚   â”œâ”€â”€ rate_limiter.py   # Sliding window implementation (Lua script)
â”‚   â””â”€â”€ analytics.py      # Request/violation logging
â”œâ”€â”€ docker-compose.yml    # Local dev stack (API + Redis)
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ requirements.txt
â””â”€â”€ redis.conf
```

---

## ğŸš€ Quick Start

```bash
# Clone and run
git clone https://github.com/cyb3rcr4t0712/distributed-rate-limiter.git
cd distributed-rate-limiter
docker-compose up --build

# Health check
curl http://localhost:8000/health

# Test rate limiting (100 req/min limit)
for i in {1..110}; do \
  curl -s -o /dev/null -w "%{http_code}\n" \
  -X POST -H "X-API-Key: test" \
  http://localhost:8000/api/resource; \
done
# First 100 return 200, then 429s kick in
```

---

## ğŸ“¡ API Reference

| Method | Endpoint | Description |
|--------|----------|-------------|
| `GET` | `/health` | Health check (bypasses rate limit) |
| `GET` | `/` | Root endpoint |
| `POST` | `/api/resource` | Protected resource |

**Headers Returned:**
```
X-RateLimit-Limit: 100
X-RateLimit-Remaining: 42
```

**Rate Limited Response:**
```json
HTTP 429
{"detail": "Too many requests. Please retry later."}
```

---

## âš™ï¸ Configuration

| Variable | Default | Description |
|----------|---------|-------------|
| `REDIS_URL` | `redis://localhost:6379` | Redis connection string |
| `DEFAULT_LIMIT` | `100` | Requests per window |
| `DEFAULT_WINDOW` | `60000` | Window size (ms) |

---

## â˜ï¸ Cloud Deployment

Designed for deployment on **Google Cloud Run** with **Redis Cloud** (or GCP Memorystore).

```bash
# Build & push to Artifact Registry
gcloud builds submit --tag us-central1-docker.pkg.dev/PROJECT/rate-limiter-repo/rate-limiter:latest .

# Deploy to Cloud Run
gcloud run deploy rate-limiter-api \
  --image=us-central1-docker.pkg.dev/PROJECT/rate-limiter-repo/rate-limiter:latest \
  --set-env-vars="REDIS_URL=rediss://default:PASS@HOST:PORT" \
  --allow-unauthenticated
```

---

## ğŸ“ˆ Future Improvements

- [ ] Per-client configurable rate limits
- [ ] Prometheus metrics export
- [ ] Admin dashboard
- [ ] Global rate limiting across regions

---

## ğŸ“„ License

MIT License Â© 2026 Shreyash
